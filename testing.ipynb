{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6776193b-3c22-4969-825e-8c81da6b3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import statistics\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import collections\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make(\"ALE/IceHockey-v5\", obs_type=\"rgb\")\n",
    "\n",
    "seed = 21\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps = np.finfo(np.float32).eps.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3e09cd8-12d7-4e83-ae86-a90b5cfe6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ActorCritic(Model):\n",
    "#   def __init__(\n",
    "#       self,\n",
    "#       num_actions: int,\n",
    "#       num_hidden_units: int):\n",
    "#     super().__init__()\n",
    "\n",
    "#     self.common = layers.Dense(num_hidden_units, activation=\"relu\")\n",
    "#     self.actor = layers.Dense(num_actions)\n",
    "#     self.critic = layers.Dense(1)\n",
    "\n",
    "#   def call(self, inputs: tf.Tensor):\n",
    "#     x = self.common(inputs)\n",
    "#     return self.actor(x), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7893998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class ActorCritic(Model):\n",
    "  def __init__(self, num_actions: int, num_hidden_units: int):\n",
    "    super().__init__()\n",
    "\n",
    "    # self.common = layers.Dense(num_hidden_units, activation=\"relu\")\n",
    "    self.conv0 = keras.layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', input_shape=[210, 160, 3])\n",
    "    # Convolutional layers for feature extraction\n",
    "    self.conv1 = keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "    self.pool1 = keras.layers.MaxPooling2D((2, 2))\n",
    "    self.conv2 = keras.layers.Conv2D(64, (4, 4), activation='relu')\n",
    "    self.pool2 = keras.layers.MaxPooling2D((2, 2))\n",
    "    self.conv3 = keras.layers.Conv2D(32, (5, 5), activation='relu')\n",
    "    self.pool3 = keras.layers.MaxPooling2D((2, 2))\n",
    "    self.conv4 = keras.layers.Conv2D(32, (5, 5), activation='relu')\n",
    "\n",
    "    # Flatten the output from the convolutional layers\n",
    "    self.flatten = keras.layers.Flatten()\n",
    "\n",
    "    # Hidden layer with ReLU activation\n",
    "    self.common = keras.layers.Dense(num_hidden_units, activation=\"relu\")\n",
    "\n",
    "    # Actor branch for policy\n",
    "    self.actor = keras.layers.Dense(num_actions, activation='softmax')\n",
    "\n",
    "    # Critic branch for state value estimation\n",
    "    self.critic = keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs: tf.Tensor):\n",
    "    # x = self.common(inputs)\n",
    "    x = self.conv0(inputs)\n",
    "    x = self.conv1(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.pool2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.pool3(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.common(x)\n",
    "    return self.actor(x), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e50e33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class ActorCritic(Model):\n",
    "#   def __init__(self, num_actions: int,num_hidden_units: int):\n",
    "#     super().__init__()\n",
    "\n",
    "#     # Define the convolutional layers\n",
    "#     self.conv1 = tf.keras.layers.Conv2D(\n",
    "#         filters=64, kernel_size=3, activation=\"relu\")\n",
    "#     self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "#     self.conv2 = tf.keras.layers.Conv2D(\n",
    "#         filters=64, kernel_size=4, activation=\"relu\")\n",
    "#     self.pool2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "#     self.conv3 = tf.keras.layers.Conv2D(\n",
    "#         filters=32, kernel_size=5, activation=\"relu\")\n",
    "#     self.pool3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "#     self.conv4 = tf.keras.layers.Conv2D(\n",
    "#         filters=32, kernel_size=5, activation=\"relu\")\n",
    "#     self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "#     # Define the hidden layer\n",
    "#     self.fc1 = tf.keras.layers.Dense(units=num_hidden_units, activation=\"relu\")\n",
    "\n",
    "#     # Define the actor and critic outputs\n",
    "#     self.actor = tf.keras.layers.Dense(num_actions, activation=\"softmax\")\n",
    "#     self.critic = tf.keras.layers.Dense(1)\n",
    "\n",
    "#   def call(self, inputs):\n",
    "#     x = self.conv1(inputs)\n",
    "#     x = self.pool1(x)\n",
    "#     x = self.conv2(x)\n",
    "#     x = self.pool2(x)\n",
    "#     x = self.conv3(x)\n",
    "#     x = self.pool3(x)\n",
    "#     x = self.conv4(x)\n",
    "#     x = self.flatten(x)\n",
    "#     x = self.fc1(x)\n",
    "#     actor_output = self.actor(x)\n",
    "#     critic_output = self.critic(x)\n",
    "\n",
    "#     return actor_output, critic_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75257e8c-8bf9-4721-9b5f-a4c355fea382",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = env.action_space.n\n",
    "num_hidden_units = 512\n",
    "\n",
    "model = ActorCritic(num_actions, num_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52cd04dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3506\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   3476\u001b[0m \n\u001b[1;32m   3477\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 3506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3510\u001b[0m     )\n\u001b[1;32m   3511\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   3512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3513\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3518\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[1;32m   3519\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78c2c6bd-3c90-47bd-942d-3d4ff4433726",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.numpy_function(Tout=[tf.float32, tf.int32, tf.int32])\n",
    "def env_step(action: np.ndarray):\n",
    "  \"\"\"Returns state, reward and done flag given an action.\"\"\"\n",
    "\n",
    "  state, reward, done, truncated, info = env.step(action)\n",
    "  return (state.astype(np.float32),\n",
    "          np.array(reward, np.int32),\n",
    "          np.array(done, np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "081c30b2-31ef-4e2d-b39f-ec5bd837c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(\n",
    "    initial_state: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    max_steps: int):\n",
    "    \"\"\"Runs a single episode to collect training data.\"\"\"\n",
    "    \n",
    "    action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "    \n",
    "    initial_state_shape = initial_state.shape\n",
    "    state = initial_state\n",
    "    \n",
    "    for t in tf.range(max_steps):\n",
    "        # Convert state into a batched tensor (batch size = 1)\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        \n",
    "        # Run the model and to get action probabilities and critic value\n",
    "        action_logits_t, value = model(state)\n",
    "        #action_logits_t = tf.squeeze(action_logits_t)\n",
    "        # Sample next action from the action probability distribution\n",
    "        action = tf.random.categorical(action_logits_t, 1)[0, 0]\n",
    "        action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "        \n",
    "        # Store critic values\n",
    "        values = values.write(t, tf.squeeze(value))\n",
    "        \n",
    "        # Store log probability of the action chosen\n",
    "        action_probs = action_probs.write(t, action_probs_t[0, action])\n",
    "        \n",
    "        # Apply action to the environment to get next state and reward\n",
    "        state, reward, done = env_step(action)\n",
    "        state.set_shape(initial_state_shape)\n",
    "        \n",
    "        # Store reward\n",
    "        rewards = rewards.write(t, reward)\n",
    "        \n",
    "        if tf.cast(done, tf.bool):\n",
    "          break\n",
    "    \n",
    "    action_probs = action_probs.stack()\n",
    "    values = values.stack()\n",
    "    rewards = rewards.stack()\n",
    "    \n",
    "    return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3edfd51-9e78-48bd-9d22-10430e50f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_return(\n",
    "    rewards: tf.Tensor,\n",
    "    gamma: float,\n",
    "    standardize: bool = True):\n",
    "  \"\"\"Compute expected returns per timestep.\"\"\"\n",
    "\n",
    "  n = tf.shape(rewards)[0]\n",
    "  returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "  # Start from the end of `rewards` and accumulate reward sums\n",
    "  # into the `returns` array\n",
    "  rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "  discounted_sum = tf.constant(0.0)\n",
    "  discounted_sum_shape = discounted_sum.shape\n",
    "  for i in tf.range(n):\n",
    "    reward = rewards[i]\n",
    "    discounted_sum = reward + gamma * discounted_sum\n",
    "    discounted_sum.set_shape(discounted_sum_shape)\n",
    "    returns = returns.write(i, discounted_sum)\n",
    "  returns = returns.stack()[::-1]\n",
    "\n",
    "  if standardize:\n",
    "    returns = ((returns - tf.math.reduce_mean(returns)) /\n",
    "               (tf.math.reduce_std(returns) + eps))\n",
    "\n",
    "  return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1bb60ca7-0708-4a02-802f-b0b17b569939",
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "def compute_loss(\n",
    "    action_probs: tf.Tensor,\n",
    "    values: tf.Tensor,\n",
    "    returns: tf.Tensor) -> tf.Tensor:\n",
    "  \"\"\"Computes the combined Actor-Critic loss.\"\"\"\n",
    "\n",
    "  advantage = returns - values\n",
    "\n",
    "  action_log_probs = tf.math.log(action_probs)\n",
    "  actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "\n",
    "  critic_loss = huber_loss(values, returns)\n",
    "\n",
    "  return actor_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30efa1c5-64c8-41b0-89e3-9343108a2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "@tf.function\n",
    "def train_step(\n",
    "    initial_state: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    gamma: float,\n",
    "    max_steps_per_episode: int) -> tf.Tensor:\n",
    "  \"\"\"Runs a model training step.\"\"\"\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    # Run the model for one episode to collect training data\n",
    "    action_probs, values, rewards = run_episode(\n",
    "        initial_state, model, max_steps_per_episode)\n",
    "\n",
    "    # Calculate the expected returns\n",
    "    returns = get_expected_return(rewards, gamma)\n",
    "\n",
    "    # Convert training data to appropriate TF tensor shapes\n",
    "    action_probs, values, returns = [\n",
    "        tf.expand_dims(x, 1) for x in [action_probs, values, returns]]\n",
    "\n",
    "    # Calculate the loss values to update our network\n",
    "    loss = compute_loss(action_probs, values, returns)\n",
    "\n",
    "  # Compute the gradients from the loss\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "  # Apply the gradients to the model's parameters\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  episode_reward = tf.math.reduce_sum(rewards)\n",
    "\n",
    "  return episode_reward\n",
    "  #return episode_reward if episode_reward is not None else -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "50abbfef-b4e7-4920-a7db-9e54700a65c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-05-08 17:04:41.996671: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fabe4abf0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-08 17:04:41.996723: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-05-08 17:04:42.010976: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715184282.093969   20660 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  0%|          | 1/1000 [00:04<1:21:07,  4.87s/it, episode_reward=0, running_reward=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: average reward: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:11<12:00,  1.37it/s, episode_reward=0, running_reward=0.0909]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10: average reward: 0.09090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [00:18<10:55,  1.49it/s, episode_reward=-1, running_reward=-0.0476]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20: average reward: -0.047619047619047616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [00:25<10:51,  1.49it/s, episode_reward=-1, running_reward=-0.0645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30: average reward: -0.06451612903225806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [00:31<10:21,  1.54it/s, episode_reward=0, running_reward=-0.0488] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40: average reward: -0.04878048780487805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [00:38<10:22,  1.52it/s, episode_reward=0, running_reward=-0.0392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50: average reward: -0.0392156862745098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 61/1000 [00:44<10:26,  1.50it/s, episode_reward=0, running_reward=-0.0328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60: average reward: -0.03278688524590164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1000 [00:51<10:09,  1.52it/s, episode_reward=0, running_reward=-0.0282]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 70: average reward: -0.028169014084507043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1000 [00:58<10:09,  1.51it/s, episode_reward=0, running_reward=-0.0247]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 80: average reward: -0.024691358024691357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 91/1000 [01:04<09:52,  1.53it/s, episode_reward=0, running_reward=-0.022] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 90: average reward: -0.02197802197802198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [01:11<10:15,  1.46it/s, episode_reward=0, running_reward=-0.0198]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100: average reward: -0.019801980198019802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 111/1000 [01:17<09:41,  1.53it/s, episode_reward=0, running_reward=-0.018] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 110: average reward: -0.018018018018018018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 121/1000 [01:24<09:38,  1.52it/s, episode_reward=0, running_reward=-0.0165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 120: average reward: -0.01652892561983471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 131/1000 [01:30<09:17,  1.56it/s, episode_reward=0, running_reward=-0.0153]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 130: average reward: -0.015267175572519083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 141/1000 [01:37<08:59,  1.59it/s, episode_reward=0, running_reward=-0.0142]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 140: average reward: -0.014184397163120567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [01:44<09:24,  1.50it/s, episode_reward=0, running_reward=-0.0132]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 150: average reward: -0.013245033112582781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 161/1000 [01:50<09:46,  1.43it/s, episode_reward=0, running_reward=-0.0124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 160: average reward: -0.012422360248447204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 171/1000 [01:56<08:01,  1.72it/s, episode_reward=0, running_reward=-0.0117]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 170: average reward: -0.011695906432748537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [02:03<08:53,  1.54it/s, episode_reward=0, running_reward=-0.011] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 180: average reward: -0.011049723756906077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 191/1000 [02:09<07:32,  1.79it/s, episode_reward=0, running_reward=-0.0105]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 190: average reward: -0.010471204188481676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [02:15<09:12,  1.45it/s, episode_reward=0, running_reward=-0.00995]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200: average reward: -0.009950248756218905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 211/1000 [02:22<08:17,  1.59it/s, episode_reward=0, running_reward=-0.00948]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 210: average reward: -0.009478672985781991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 221/1000 [02:28<08:18,  1.56it/s, episode_reward=0, running_reward=-0.00905]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 220: average reward: -0.00904977375565611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 231/1000 [02:35<08:40,  1.48it/s, episode_reward=0, running_reward=-0.00866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 230: average reward: -0.008658008658008658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 241/1000 [02:41<08:23,  1.51it/s, episode_reward=0, running_reward=-0.0083] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 240: average reward: -0.008298755186721992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [02:48<08:18,  1.50it/s, episode_reward=0, running_reward=-0.00797]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 250: average reward: -0.00796812749003984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 261/1000 [02:55<08:04,  1.53it/s, episode_reward=0, running_reward=-0.00766]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 260: average reward: -0.007662835249042145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 271/1000 [03:01<08:05,  1.50it/s, episode_reward=0, running_reward=-0.00738]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 270: average reward: -0.007380073800738007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 281/1000 [03:08<08:12,  1.46it/s, episode_reward=0, running_reward=-0.00712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 280: average reward: -0.0071174377224199285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 291/1000 [03:15<08:54,  1.33it/s, episode_reward=0, running_reward=-0.00687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 290: average reward: -0.006872852233676976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [03:22<07:46,  1.50it/s, episode_reward=0, running_reward=-0.00664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300: average reward: -0.006644518272425249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 311/1000 [03:29<07:30,  1.53it/s, episode_reward=0, running_reward=-0.00643]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 310: average reward: -0.006430868167202572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [03:36<07:40,  1.48it/s, episode_reward=0, running_reward=-0.00623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 320: average reward: -0.006230529595015576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 331/1000 [03:42<07:51,  1.42it/s, episode_reward=0, running_reward=-0.00604]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 330: average reward: -0.006042296072507553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 341/1000 [03:50<08:05,  1.36it/s, episode_reward=0, running_reward=-0.00587]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 340: average reward: -0.005865102639296188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [03:56<07:14,  1.49it/s, episode_reward=0, running_reward=-0.0057] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 350: average reward: -0.005698005698005698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 361/1000 [04:03<06:56,  1.53it/s, episode_reward=0, running_reward=-0.00554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 360: average reward: -0.00554016620498615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 371/1000 [04:09<07:05,  1.48it/s, episode_reward=0, running_reward=-0.00539]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 370: average reward: -0.005390835579514825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 381/1000 [04:16<07:04,  1.46it/s, episode_reward=0, running_reward=-0.00525]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 380: average reward: -0.005249343832020997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 391/1000 [04:23<06:50,  1.48it/s, episode_reward=0, running_reward=-0.00512]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 390: average reward: -0.005115089514066497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [04:30<06:34,  1.52it/s, episode_reward=0, running_reward=-0.00499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400: average reward: -0.004987531172069825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 411/1000 [04:36<06:30,  1.51it/s, episode_reward=0, running_reward=-0.00487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 410: average reward: -0.004866180048661801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 421/1000 [04:43<06:23,  1.51it/s, episode_reward=0, running_reward=-0.00475]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 420: average reward: -0.004750593824228029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 431/1000 [04:49<05:46,  1.64it/s, episode_reward=0, running_reward=-0.00464]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 430: average reward: -0.004640371229698376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 441/1000 [04:55<05:19,  1.75it/s, episode_reward=0, running_reward=-0.00454]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 440: average reward: -0.0045351473922902496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [05:01<05:20,  1.71it/s, episode_reward=0, running_reward=-0.00443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 450: average reward: -0.004434589800443459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 461/1000 [05:07<05:14,  1.72it/s, episode_reward=0, running_reward=-0.00434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 460: average reward: -0.004338394793926247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 471/1000 [05:12<05:12,  1.69it/s, episode_reward=0, running_reward=-0.00425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 470: average reward: -0.004246284501061571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 481/1000 [05:18<05:00,  1.73it/s, episode_reward=0, running_reward=-0.00416]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 480: average reward: -0.004158004158004158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [05:24<04:55,  1.72it/s, episode_reward=0, running_reward=-0.00407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 490: average reward: -0.004073319755600814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [05:30<04:48,  1.73it/s, episode_reward=0, running_reward=-0.00399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500: average reward: -0.003992015968063872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 511/1000 [05:36<04:52,  1.67it/s, episode_reward=0, running_reward=-0.00391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 510: average reward: -0.003913894324853229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 521/1000 [05:42<04:42,  1.70it/s, episode_reward=0, running_reward=-0.00384]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 520: average reward: -0.003838771593090211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 531/1000 [05:48<04:39,  1.68it/s, episode_reward=0, running_reward=-0.00377]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 530: average reward: -0.003766478342749529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 541/1000 [05:54<04:30,  1.70it/s, episode_reward=0, running_reward=-0.0037] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 540: average reward: -0.0036968576709796672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [06:00<04:18,  1.73it/s, episode_reward=0, running_reward=-0.00363]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 550: average reward: -0.003629764065335753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 561/1000 [06:05<04:01,  1.82it/s, episode_reward=0, running_reward=-0.00357]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 560: average reward: -0.0035650623885918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 571/1000 [06:11<03:58,  1.80it/s, episode_reward=0, running_reward=-0.0035] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 570: average reward: -0.0035026269702276708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 581/1000 [06:16<03:56,  1.77it/s, episode_reward=0, running_reward=-0.00344]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 580: average reward: -0.0034423407917383822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 591/1000 [06:22<03:44,  1.82it/s, episode_reward=0, running_reward=-0.00338]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 590: average reward: -0.00338409475465313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [06:28<03:41,  1.80it/s, episode_reward=0, running_reward=-0.00333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600: average reward: -0.0033277870216306157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 611/1000 [06:33<03:44,  1.73it/s, episode_reward=0, running_reward=-0.00327]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 610: average reward: -0.0032733224222585926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 621/1000 [06:39<03:38,  1.73it/s, episode_reward=0, running_reward=-0.00322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 620: average reward: -0.00322061191626409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 631/1000 [06:45<03:29,  1.76it/s, episode_reward=0, running_reward=-0.00317]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 630: average reward: -0.003169572107765452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 641/1000 [06:50<03:22,  1.77it/s, episode_reward=0, running_reward=-0.00312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 640: average reward: -0.0031201248049922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [06:56<03:18,  1.76it/s, episode_reward=0, running_reward=-0.00307]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 650: average reward: -0.0030721966205837174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 661/1000 [07:02<03:07,  1.81it/s, episode_reward=0, running_reward=-0.00303]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 660: average reward: -0.0030257186081694403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 671/1000 [07:07<03:04,  1.78it/s, episode_reward=0, running_reward=-0.00298]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 670: average reward: -0.0029806259314456036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 681/1000 [07:13<03:01,  1.76it/s, episode_reward=0, running_reward=-0.00294]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 680: average reward: -0.002936857562408223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 691/1000 [07:19<02:54,  1.77it/s, episode_reward=0, running_reward=-0.00289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 690: average reward: -0.002894356005788712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [07:24<02:49,  1.77it/s, episode_reward=0, running_reward=-0.00285]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700: average reward: -0.0028530670470756064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 711/1000 [07:30<02:40,  1.80it/s, episode_reward=0, running_reward=-0.00281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 710: average reward: -0.0028129395218002813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 721/1000 [07:35<02:38,  1.76it/s, episode_reward=0, running_reward=-0.00277]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 720: average reward: -0.0027739251040221915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 731/1000 [07:41<02:37,  1.71it/s, episode_reward=0, running_reward=-0.00274]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 730: average reward: -0.0027359781121751026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 741/1000 [07:47<02:25,  1.78it/s, episode_reward=0, running_reward=-0.0027] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 740: average reward: -0.002699055330634278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [07:53<02:21,  1.76it/s, episode_reward=0, running_reward=-0.00266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 750: average reward: -0.002663115845539281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 761/1000 [07:58<02:17,  1.74it/s, episode_reward=0, running_reward=-0.00263]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 760: average reward: -0.002628120893561104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 771/1000 [08:04<02:14,  1.70it/s, episode_reward=0, running_reward=-0.00259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 770: average reward: -0.0025940337224383916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 781/1000 [08:10<02:06,  1.73it/s, episode_reward=0, running_reward=-0.00256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 780: average reward: -0.002560819462227913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 791/1000 [08:16<02:01,  1.73it/s, episode_reward=0, running_reward=-0.00253]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 790: average reward: -0.0025284450063211127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [08:22<01:56,  1.71it/s, episode_reward=0, running_reward=-0.0025] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800: average reward: -0.0024968789013732834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 811/1000 [08:28<01:48,  1.74it/s, episode_reward=0, running_reward=-0.00247]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 810: average reward: -0.002466091245376079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 821/1000 [08:33<01:42,  1.74it/s, episode_reward=0, running_reward=-0.00244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 820: average reward: -0.00243605359317905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 831/1000 [08:39<01:35,  1.77it/s, episode_reward=0, running_reward=-0.00241]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 830: average reward: -0.0024067388688327317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 841/1000 [08:45<01:30,  1.76it/s, episode_reward=0, running_reward=-0.00238]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 840: average reward: -0.0023781212841854932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [08:50<01:22,  1.80it/s, episode_reward=0, running_reward=-0.00235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 850: average reward: -0.0023501762632197414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 861/1000 [08:56<01:20,  1.73it/s, episode_reward=0, running_reward=-0.00232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 860: average reward: -0.0023228803716608595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 871/1000 [09:02<01:14,  1.74it/s, episode_reward=0, running_reward=-0.0023] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 870: average reward: -0.002296211251435132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 881/1000 [09:08<01:08,  1.75it/s, episode_reward=0, running_reward=-0.00227]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 880: average reward: -0.0022701475595913734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 891/1000 [09:13<01:01,  1.79it/s, episode_reward=0, running_reward=-0.00224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 890: average reward: -0.002244668911335578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [09:19<00:56,  1.76it/s, episode_reward=0, running_reward=-0.00222]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900: average reward: -0.0022197558268590455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 911/1000 [09:25<00:51,  1.74it/s, episode_reward=0, running_reward=-0.0022] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 910: average reward: -0.0021953896816684962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 921/1000 [09:31<00:45,  1.75it/s, episode_reward=0, running_reward=-0.00217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 920: average reward: -0.002171552660152009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 931/1000 [09:36<00:39,  1.73it/s, episode_reward=0, running_reward=-0.00215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 930: average reward: -0.0021482277121374865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 941/1000 [09:42<00:33,  1.79it/s, episode_reward=0, running_reward=-0.00213]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 940: average reward: -0.0021253985122210413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [09:48<00:28,  1.74it/s, episode_reward=0, running_reward=-0.0021] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 950: average reward: -0.002103049421661409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 961/1000 [09:53<00:22,  1.75it/s, episode_reward=0, running_reward=-0.00208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 960: average reward: -0.002081165452653486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 971/1000 [09:59<00:16,  1.77it/s, episode_reward=0, running_reward=-0.00206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 970: average reward: -0.0020597322348094747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 981/1000 [10:05<00:10,  1.76it/s, episode_reward=0, running_reward=-0.00204]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 980: average reward: -0.0020387359836901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 991/1000 [10:10<00:05,  1.80it/s, episode_reward=0, running_reward=-0.00202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 990: average reward: -0.0020181634712411706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [10:16<00:00,  1.62it/s, episode_reward=0, running_reward=-0.002] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solved at episode 999: average reward: -0.00!\n",
      "CPU times: user 8min 28s, sys: 4min 57s, total: 13min 26s\n",
      "Wall time: 10min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "min_episodes_criterion = 50\n",
    "max_episodes = 1000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "reward_threshold = 0\n",
    "running_reward = 0\n",
    "\n",
    "# The discount factor for future rewards\n",
    "gamma = 0.99\n",
    "\n",
    "# Keep the last episodes reward\n",
    "episodes_reward = []\n",
    "\n",
    "t = tqdm.trange(max_episodes)\n",
    "with tf.device('/GPU:0'):\n",
    "    for i in t:\n",
    "        initial_state, info = env.reset()\n",
    "        initial_state = tf.constant(initial_state, dtype=tf.float32)\n",
    "        # initial_state = tf.squeeze(initial_state)\n",
    "        # initial_state = initial_state[:, :]\n",
    "        # initial_state = tf.expand_dims(initial_state, axis=0)\n",
    "        episode_reward = int(train_step(\n",
    "            initial_state, model, optimizer, gamma, max_steps_per_episode))\n",
    "\n",
    "        episodes_reward.append(episode_reward)\n",
    "        running_reward = statistics.mean(episodes_reward)\n",
    "\n",
    "        t.set_postfix(\n",
    "            episode_reward=episode_reward, running_reward=running_reward)\n",
    "\n",
    "        # Show the average episode reward every 10 episodesa\n",
    "        if i % 10 == 0:\n",
    "            print(f'Episode {i}: average reward: {running_reward}')\n",
    "            pass # \n",
    "\n",
    "        #ice hockey doesn't have a reward threshold as there is no score limit\n",
    "        if running_reward > reward_threshold and i >= min_episodes_criterion:\n",
    "           break\n",
    "\n",
    "print(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c8a00be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_20561/4271716241.py\", line 15, in train_step  *\n        action_probs, values, rewards = run_episode(\n    File \"/tmp/ipykernel_20561/1145069195.py\", line 19, in run_episode  *\n        action_logits_t, value = model(state)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file0m4u5zi_.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'actor_critic_7' (type ActorCritic).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_20561/3262233582.py\", line 33, in call  *\n            x = self.conv1(x)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 354, in compute_output_shape\n            raise ValueError(\n    \n        ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv2d_29. Consider increasing the input size. Received input shape [1, 1, 210, 32] which would produce output shape with a zero or negative value in a dimension.\n    \n    \n    Call arguments received by layer 'actor_critic_7' (type ActorCritic):\n      • inputs=tf.Tensor(shape=(1, 1, 210, 160), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file3_xrs1vy.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(initial_state, model, optimizer, gamma, max_steps_per_episode)\u001b[0m\n\u001b[1;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 12\u001b[0m     (action_probs, values, rewards) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_episode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps_per_episode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     returns \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(get_expected_return), (ag__\u001b[38;5;241m.\u001b[39mld(rewards), ag__\u001b[38;5;241m.\u001b[39mld(gamma)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m     (action_probs, values, returns) \u001b[38;5;241m=\u001b[39m [ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(x), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [ag__\u001b[38;5;241m.\u001b[39mld(action_probs), ag__\u001b[38;5;241m.\u001b[39mld(values), ag__\u001b[38;5;241m.\u001b[39mld(returns)]]\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0_jdsdlw.py:68\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_episode\u001b[0;34m(initial_state, model, max_steps)\u001b[0m\n\u001b[1;32m     66\u001b[0m reward \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m action \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction_probs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrewards\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbreak_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m action_probs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(action_probs)\u001b[38;5;241m.\u001b[39mstack, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     70\u001b[0m values \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(values)\u001b[38;5;241m.\u001b[39mstack, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0_jdsdlw.py:31\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_episode.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     29\u001b[0m (break_,)\n\u001b[1;32m     30\u001b[0m state \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(state), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 31\u001b[0m (action_logits_t, value) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m action \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mcategorical, (ag__\u001b[38;5;241m.\u001b[39mld(action_logits_t), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m action_probs_t \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax, (ag__\u001b[38;5;241m.\u001b[39mld(action_logits_t),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0m4u5zi_.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconv0, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mpool1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconv2, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_20561/4271716241.py\", line 15, in train_step  *\n        action_probs, values, rewards = run_episode(\n    File \"/tmp/ipykernel_20561/1145069195.py\", line 19, in run_episode  *\n        action_logits_t, value = model(state)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file0m4u5zi_.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'actor_critic_7' (type ActorCritic).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_20561/3262233582.py\", line 33, in call  *\n            x = self.conv1(x)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 354, in compute_output_shape\n            raise ValueError(\n    \n        ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv2d_29. Consider increasing the input size. Received input shape [1, 1, 210, 32] which would produce output shape with a zero or negative value in a dimension.\n    \n    \n    Call arguments received by layer 'actor_critic_7' (type ActorCritic):\n      • inputs=tf.Tensor(shape=(1, 1, 210, 160), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# min_episodes_criterion = 50\n",
    "# max_episodes = 1000\n",
    "# max_steps_per_episode = 1000\n",
    "\n",
    "# reward_threshold = 0\n",
    "# running_reward = 0\n",
    "\n",
    "# # The discount factor for future rewards\n",
    "# gamma = 0.99\n",
    "\n",
    "# # Keep the last episodes reward\n",
    "# episodes_reward = []\n",
    "\n",
    "# t = tqdm.trange(max_episodes)\n",
    "# with tf.device('/GPU:0'):\n",
    "#     for i in t:\n",
    "#         initial_state, info = env.reset()\n",
    "#         initial_state = tf.constant(initial_state, dtype=tf.float32)\n",
    "#         initial_state = tf.expand_dims(initial_state, axis=0)\n",
    "#         episode_reward = int(train_step(\n",
    "#             initial_state, model, optimizer, gamma, max_steps_per_episode))\n",
    "\n",
    "#         episodes_reward.append(episode_reward)\n",
    "#         running_reward = statistics.mean(episodes_reward)\n",
    "\n",
    "#         t.set_postfix(\n",
    "#             episode_reward=episode_reward, running_reward=running_reward)\n",
    "\n",
    "#         # Show the average episode reward every 10 episodes\n",
    "#         if i % 10 == 0:\n",
    "#             print(f'Episode {i}: average reward: {running_reward}')\n",
    "\n",
    "#         # Ice hockey doesn't have a reward threshold as there is no score limit\n",
    "#         if running_reward > reward_threshold and i >= min_episodes_criterion:\n",
    "#            break\n",
    "\n",
    "# print(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8386e786-d6d0-4c8d-9d50-b5000a3741e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.005, 0.001)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes_reward)\n",
    "plt.ylim(-0.005,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ecba56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int):\n",
    "  state, info = env.reset()\n",
    "  state = tf.constant(state, dtype=tf.float32)\n",
    "  screen = env.render()\n",
    "  images = [Image.fromarray(screen)]\n",
    "  flatten = Flatten()\n",
    "\n",
    "  for i in range(1, max_steps + 1):\n",
    "    state=tf.expand_dims(state, axis=0)\n",
    "    action_probs, _ = model(state)\n",
    "    action = np.argmax(np.squeeze(action_probs[0][0]))\n",
    "      \n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 10 == 0:\n",
    "      screen = env.render()\n",
    "      images.append(Image.fromarray(screen))\n",
    "\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bc894b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "\n",
    "render_env = gym.make(\"ALE/IceHockey-v5\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Save GIF image\n",
    "images = render_episode(render_env, model, 500)\n",
    "image_file = 'Icehockey-v5.gif'\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5405b72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/gif;base64,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\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82028d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
